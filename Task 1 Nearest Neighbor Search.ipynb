{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f46f60",
   "metadata": {},
   "source": [
    "## Task 1: Nearest Neighbor Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd03cc8",
   "metadata": {},
   "source": [
    "### Step 1: Loading and Parsing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52f5e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries \n",
    "import time\n",
    "import math\n",
    "import heapq\n",
    "from rtree import index\n",
    "import numpy as np\n",
    "\n",
    "# Function to load the parking dataset from a file\n",
    "def load_dataset(file_path):\n",
    "    dataset = []  # Initialize an empty list to hold the dataset\n",
    "    with open(\"Task1_Datasets/parking_dataset.txt\", 'r') as f:  # Open the dataset file in read mode\n",
    "        for line in f:  # Iterate over each line in the file\n",
    "            parts = line.strip().split()  # Split the line into parts based on whitespace\n",
    "            id, x, y = int(parts[0]), float(parts[1]), float(parts[2])  # Convert parts to appropriate data types\n",
    "            dataset.append((id, x, y))  # Append the tuple (id, x, y) to the dataset list\n",
    "    return dataset  # Return the loaded dataset\n",
    "\n",
    "# Function to load the query points from a file\n",
    "def load_queries(file_path):\n",
    "    queries = []  # Initialize an empty list to hold the query points\n",
    "    with open(\"Task1_Datasets/query_points.txt\", 'r') as f:  # Open the query points file in read mode\n",
    "        for line in f:  # Iterate over each line in the file\n",
    "            parts = line.strip().split()  # Split the line into parts based on whitespace\n",
    "            id, x, y = int(parts[0]), float(parts[1]), float(parts[2])  # Convert parts to appropriate data types\n",
    "            queries.append((id, x, y))  # Append the tuple (id, x, y) to the queries list\n",
    "    return queries  # Return the loaded query points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e782f48",
   "metadata": {},
   "source": [
    "### Step 2: Implementing the Nearest Neighbor Search Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372bd97",
   "metadata": {},
   "source": [
    "#### 1. Sequential Scan Based Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b5a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Euclidean distance between two points.\n",
    "def euclidean_distance(point1, point2):\n",
    "    return math.sqrt((point1[1] - point2[1])**2 + (point1[2] - point2[2])**2)  # Compute and return the Euclidean distance\n",
    "\n",
    "# Finding the nearest neighbor for each query using the sequential scan method.\n",
    "def sequential_scan(dataset, queries):\n",
    "    results = []  # Initialize an empty list to hold the nearest neighbors\n",
    "    start_time = time.time()  # Record the start time of the process\n",
    "    for q in queries:  # Iterate over each query point\n",
    "        nearest = min(dataset, key=lambda p: euclidean_distance(p, q))  # Find the nearest neighbor in the dataset\n",
    "        results.append(nearest)  # Append the nearest neighbor to the results list\n",
    "    total_time = time.time() - start_time  # Calculate the total time taken for all queries\n",
    "    average_time = total_time / len(queries)  # Calculate the average time taken per query\n",
    "    return results, total_time, average_time  # Return the nearest neighbors, total time taken, and average time per query\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca9dc92",
   "metadata": {},
   "source": [
    "#### 2. Best First (BF) Algorithm Using R-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42f96265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing an R-tree from the dataset.\n",
    "def construct_rtree(dataset):\n",
    "    p = index.Property()  # Create an R-tree property object\n",
    "    rtree = index.Index(properties=p)  # Initialize an R-tree index with the specified properties\n",
    "    for idx, point in enumerate(dataset):  # Iterate over each point in the dataset with its index\n",
    "        # Insert the point into the R-tree with its index, bounding box, and object\n",
    "        rtree.insert(idx, (point[1], point[2], point[1], point[2]), obj=point)\n",
    "    return rtree  # Return the constructed R-tree\n",
    "\n",
    "# Finding the nearest neighbor for each query using the Best First search method with an R-tree.\n",
    "def best_first_search(rtree, queries):\n",
    "    results = []  # Initialize an empty list to hold the nearest neighbors\n",
    "    start_time = time.time()  # Record the start time of the process\n",
    "    for q in queries:  # Iterate over each query point\n",
    "        # Find the nearest neighbor using the R-tree and convert the result to a list, then get the object\n",
    "        nearest = list(rtree.nearest((q[1], q[2], q[1], q[2]), 1, objects=True))[0].object\n",
    "        results.append(nearest)  # Append the nearest neighbor to the results list\n",
    "    total_time = time.time() - start_time  # Calculate the total time taken for all queries\n",
    "    average_time = total_time / len(queries)  # Calculate the average time taken per query\n",
    "    return results, total_time, average_time  # Return the nearest neighbors, total time taken, and average time per query\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e90b39",
   "metadata": {},
   "source": [
    "#### 3. BF with Divide-and-Conquer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d6c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset into two subspaces based on the median x value\n",
    "def divide_dataset(dataset):\n",
    "    mid_x = np.median([point[1] for point in dataset])  # Calculate the median x value of the dataset points\n",
    "    # Create a sublist of points in the left subspace (x <= median x)\n",
    "    left_subspace = [point for point in dataset if point[1] <= mid_x]\n",
    "    # Create a sublist of points in the right subspace (x > median x)\n",
    "    right_subspace = [point for point in dataset if point[1] > mid_x]\n",
    "    return left_subspace, right_subspace  # Return two sublists of the dataset points\n",
    "\n",
    "# Finding the nearest neighbor for each query using the BF with Divide-and-Conquer method.\n",
    "def bf_with_divide_and_conquer(dataset, queries):\n",
    "    left_subspace, right_subspace = divide_dataset(dataset)  # Divide the dataset into two subspaces\n",
    "    rtree_left = construct_rtree(left_subspace)  # Construct an R-tree for the left subspace\n",
    "    rtree_right = construct_rtree(right_subspace)  # Construct an R-tree for the right subspace\n",
    "    \n",
    "    results = []  # Initialize an empty list to hold the nearest neighbors\n",
    "    start_time = time.time()  # Record the start time of the process\n",
    "    for q in queries:  # Iterate over each query point\n",
    "        # Find the nearest neighbor in the left subspace using the R-tree\n",
    "        nearest_left = list(rtree_left.nearest((q[1], q[2], q[1], q[2]), 1, objects=True))[0].object\n",
    "        # Find the nearest neighbor in the right subspace using the R-tree\n",
    "        nearest_right = list(rtree_right.nearest((q[1], q[2], q[1], q[2]), 1, objects=True))[0].object\n",
    "        # Compare distances to determine the closer neighbor\n",
    "        if euclidean_distance(nearest_left, q) < euclidean_distance(nearest_right, q):\n",
    "            results.append(nearest_left)  # Append the nearest neighbor from the left subspace\n",
    "        else:\n",
    "            results.append(nearest_right)  # Append the nearest neighbor from the right subspace\n",
    "    total_time = time.time() - start_time  # Calculate the total time taken for all queries\n",
    "    average_time = total_time / len(queries)  # Calculate the average time taken per query\n",
    "    return results, total_time, average_time  # Return the nearest neighbors, total time taken, and average time per query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21a821d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results into the file.\n",
    "# Arguments for save_results:\n",
    "\"\"\"\n",
    "results : List of nearest neighbors for each query.\n",
    "method_name : Name of the method used to obtain the results.\n",
    "total_time : Total time taken for all queries (float).\n",
    "average_time : Average time taken per query (float).\n",
    "file_path : Path to the output file.\n",
    "\"\"\"\n",
    "\n",
    "def save_results(results, method_name, total_time, average_time, file_path):\n",
    "    # Open the file in append mode and write the results\n",
    "    with open(file_path, 'a') as f:\n",
    "        f.write(f\"Results for {method_name}:\\n\")  # Write method name to the file\n",
    "        # Write each result to the file\n",
    "        for i, result in enumerate(results):\n",
    "            f.write(f\"id={result[0]}, x={result[1]}, y={result[2]} for query {i+1}\\n\")\n",
    "        # Write total running time for all queries to the file\n",
    "        f.write(f\"Total running time for processing all queries: {total_time:.6f} seconds\\n\")\n",
    "        # Write average time per query to the file\n",
    "        f.write(f\"Average time per query: {average_time:.6f} seconds\\n\\n\")\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"Task_1_results.txt\"\n",
    "# Load data\n",
    "parking_dataset = load_dataset('Task1_Datasets/parking_dataset.txt')\n",
    "query_points = load_queries('Task1_Datasets/query_points.txt')\n",
    "\n",
    "# Saving Sequential Scan result\n",
    "seq_results, seq_total_time, seq_avg_time = sequential_scan(parking_dataset, query_points)\n",
    "# Call save_results function to save the Sequential Scan result\n",
    "save_results(seq_results, 'Sequential Scan Based', seq_total_time, seq_avg_time, file_path)\n",
    "\n",
    "# Saving Best First Search using R-tree result\n",
    "rtree = construct_rtree(parking_dataset)\n",
    "bf_results, bf_total_time, bf_avg_time = best_first_search(rtree, query_points)\n",
    "# Call save_results function to save the Best First Search using R-tree result\n",
    "save_results(bf_results, 'BF Algorithm', bf_total_time, bf_avg_time, file_path)\n",
    "\n",
    "# Saving BF with Divide-and-Conquer result\n",
    "bf_dc_results, bf_dc_total_time, bf_dc_avg_time = bf_with_divide_and_conquer(parking_dataset, query_points)\n",
    "# Call save_results function to save the BF with Divide-and-Conquer result\n",
    "save_results(bf_dc_results, 'BF with Divide-and-Conquer', bf_dc_total_time, bf_dc_avg_time, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d6448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f39c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
